{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBh9nhGJ6VWT"
      },
      "source": [
        "# A Survey on Attention Mechanisms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VvyYOqXfes0"
      },
      "source": [
        "### References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_wSaCgU6S1m"
      },
      "source": [
        "```\n",
        "@misc{minimax2025minimax01scalingfoundationmodels,\n",
        "      title={MiniMax-01: Scaling Foundation Models with Lightning Attention},\n",
        "      author={MiniMax and Aonian Li and Bangwei Gong and Bo Yang and Boji Shan and Chang Liu and Cheng Zhu and Chunhao Zhang and Congchao Guo and Da Chen and Dong Li and Enwei Jiao and Gengxin Li and Guojun Zhang and Haohai Sun and Houze Dong and Jiadai Zhu and Jiaqi Zhuang and Jiayuan Song and Jin Zhu and Jingtao Han and Jingyang Li and Junbin Xie and Junhao Xu and Junjie Yan and Kaishun Zhang and Kecheng Xiao and Kexi Kang and Le Han and Leyang Wang and Lianfei Yu and Liheng Feng and Lin Zheng and Linbo Chai and Long Xing and Meizhi Ju and Mingyuan Chi and Mozhi Zhang and Peikai Huang and Pengcheng Niu and Pengfei Li and Pengyu Zhao and Qi Yang and Qidi Xu and Qiexiang Wang and Qin Wang and Qiuhui Li and Ruitao Leng and Shengmin Shi and Shuqi Yu and Sichen Li and Songquan Zhu and Tao Huang and Tianrun Liang and Weigao Sun and Weixuan Sun and Weiyu Cheng and Wenkai Li and Xiangjun Song and Xiao Su and Xiaodong Han and Xinjie Zhang and Xinzhu Hou and Xu Min and Xun Zou and Xuyang Shen and Yan Gong and Yingjie Zhu and Yipeng Zhou and Yiran Zhong and Yongyi Hu and Yuanxiang Fan and Yue Yu and Yufeng Yang and Yuhao Li and Yunan Huang and Yunji Li and Yunpeng Huang and Yunzhi Xu and Yuxin Mao and Zehan Li and Zekang Li and Zewei Tao and Zewen Ying and Zhaoyang Cong and Zhen Qin and Zhenhua Fan and Zhihang Yu and Zhuo Jiang and Zijia Wu},\n",
        "      year={2025},\n",
        "      eprint={2501.08313},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.CL},\n",
        "      url={https://arxiv.org/abs/2501.08313},\n",
        "}`=\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jT1oERHzfbbI"
      },
      "source": [
        "```\n",
        "@article{liu2024deepseek,\n",
        "  title={Deepseek-v2: A strong, economical, and efficient mixture-of-experts language model},\n",
        "  author={Liu, Aixin and Feng, Bei and Wang, Bin and Wang, Bingxuan and Liu, Bo and Zhao, Chenggang and Dengr, Chengqi and Ruan, Chong and Dai, Damai and Guo, Daya and others},\n",
        "  journal={arXiv preprint arXiv:2405.04434},\n",
        "  year={2024}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9dJuVwZfJB7"
      },
      "source": [
        "```\n",
        "@article{ainslie2023gqa,\n",
        "  title={Gqa: Training generalized multi-query transformer models from multi-head checkpoints},\n",
        "  author={Ainslie, Joshua and Lee-Thorp, James and De Jong, Michiel and Zemlyanskiy, Yury and Lebr{\\'o}n, Federico and Sanghai, Sumit},\n",
        "  journal={arXiv preprint arXiv:2305.13245},\n",
        "  year={2023}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpMvTpxEfn0y"
      },
      "source": [
        "```\n",
        "@article{shazeer2019fast,\n",
        "  title={Fast transformer decoding: One write-head is all you need},\n",
        "  author={Shazeer, Noam},\n",
        "  journal={arXiv preprint arXiv:1911.02150},\n",
        "  year={2019}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fsjHW6ofder"
      },
      "source": [
        "### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpcfShWRIyn5",
        "outputId": "9759a873-0a4f-4274-ac84-1f5ecd04c3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting jaxtyping\n",
            "  Downloading jaxtyping-0.2.38-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: treescope in /usr/local/lib/python3.11/dist-packages (0.1.8)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping)\n",
            "  Downloading wadler_lindig-0.1.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.25.2 in /usr/local/lib/python3.11/dist-packages (from treescope) (1.26.4)\n",
            "Downloading jaxtyping-0.2.38-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.3-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: wadler-lindig, jaxtyping\n",
            "Successfully installed jaxtyping-0.2.38 wadler-lindig-0.1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install jaxtyping treescope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YquMRQk5ACi_"
      },
      "outputs": [],
      "source": [
        "import treescope\n",
        "treescope.basic_interactive_setup(autovisualize_arrays=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dyIpHPV89cPZ"
      },
      "outputs": [],
      "source": [
        "from flax import linen as nn\n",
        "from dataclasses import dataclass\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.sharding as shd\n",
        "from jaxtyping import Float, Int, Bool, Array\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ2aqCMbD5Fd"
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV9FtFG26URk"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class MiniMaxConfig:\n",
        "    # MoE\n",
        "    ffw_hidden_size: int = 9216\n",
        "    num_experts: int = 32\n",
        "    top_k: int = 2  # top-2 routing on MoE\n",
        "    aux_loss_coef: float = 0.01\n",
        "\n",
        "    # Attn\n",
        "    num_heads: int = 64\n",
        "    head_dim: int = 128\n",
        "    group_size: int = 8  # for Group-Query Attention\n",
        "    num_layers: int = 80\n",
        "    linear_per_softmax: int = 7 # 7 transnormers, then 1 transformer\n",
        "    hidden_size: int = 6144\n",
        "\n",
        "    deepnorm_alpha: float = 0.81\n",
        "\n",
        "    # RoPE\n",
        "    rope_fraction: float = 0.5\n",
        "    rope_base_freq: float = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHfkj3lPEvyB"
      },
      "source": [
        "## Rotatory Positional Embeddings (RoPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCoAjn9mIW5t"
      },
      "source": [
        "We apply RoPE inside the attention mechanism:\n",
        "$$(Q, K) \\longrightarrow (\\tilde{Q}, \\tilde{K}) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtR1SWrWIRrn"
      },
      "source": [
        "RoPE applies a rotation to every 2D pair $(x_{2i}, x_{2i+1})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxQmav0-IKyB"
      },
      "source": [
        "$$\n",
        "\\begin{pmatrix}\n",
        "x_{2i}^{\\text{rot}} \\\\\n",
        "x_{2i+1}^{\\text{rot}}\n",
        "\\end{pmatrix}\n",
        "=\n",
        "\\begin{pmatrix}\n",
        "\\cos(\\theta_{p,i}) & -\\sin(\\theta_{p,i}) \\\\\n",
        "\\sin(\\theta_{p,i}) & \\cos(\\theta_{p,i})\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "x_{2i} \\\\[6pt]\n",
        "x_{2i+1}\n",
        "\\end{pmatrix},\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGA7h7LH7L-d"
      },
      "source": [
        "$$\\theta_i\n",
        "\\;=\\; \\frac{1}{\\bigl(\\text{rope_base_freq}\\bigr)^{\\,\\frac{2\\,i}{\\text{rot_dim}}}}\n",
        "\\quad \\text{for} \\; i=0,\\dots,\\frac{\\text{rot_dim}}{2}-1.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTlEI4P7Vsa"
      },
      "source": [
        "$$\n",
        "p \\;\\in\\; \\{0, 1, 2, \\dots, \\text{seq_len}-1\\}.\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de92BpCI7a7u"
      },
      "source": [
        "$$\\alpha_{p,i} \\;=\\; p \\cdot \\theta_i.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zDX1wJ57gAE"
      },
      "source": [
        "$$\n",
        "\\sin_{p,i} \\;=\\; \\sin(\\alpha_{p,i}),\n",
        "\\quad\n",
        "\\cos_{p,i} \\;=\\; \\cos(\\alpha_{p,i}).\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6eS4UcsBK1h"
      },
      "source": [
        "Usage:\n",
        "```\n",
        "class YourClass(nn.Module):\n",
        "    config: MiniMaxConfig\n",
        "\n",
        "    def setup(self):\n",
        "        self.rope = RotatoryPositionEmbedding(config=config)\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        q_rot, k_rot = self.rope(q, k)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcahqR_iE1vq"
      },
      "outputs": [],
      "source": [
        "class RotaryPositionEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    A Flax module that applies partial Rotary Position Embeddings (RoPE) to\n",
        "    query and key tensors. By default, only a fraction of each head dimension\n",
        "    (specified by `rope_fraction`) is rotated, and the remaining dimensions\n",
        "    remain unaltered.\n",
        "\n",
        "    Attributes:\n",
        "        config (MiniMaxConfig): A configuration object specifying RoPE fraction\n",
        "            and base frequency.\n",
        "    \"\"\"\n",
        "    config: MiniMaxConfig\n",
        "\n",
        "    def _get_rotary_matrix(\n",
        "        self,\n",
        "        seq_len: int,\n",
        "        rot_dim: int\n",
        "    ) -> Tuple[Float[Array, \"seq rot_dim//2\"], Float[Array, \"seq rot_dim//2\"]]:\n",
        "        \"\"\"\n",
        "        Generate the sine and cosine matrices for the rotary transformations.\n",
        "\n",
        "        Args:\n",
        "            seq_len (int): Length of the sequence (number of positions).\n",
        "            rot_dim (int): Number of head-dimension channels to which\n",
        "                           RoPE is applied.\n",
        "\n",
        "        Returns:\n",
        "            sin (Float[Array, \"seq rot_dim//2\"]):\n",
        "                The sine values, shape = [seq_len, rot_dim//2].\n",
        "            cos (Float[Array, \"seq rot_dim//2\"]):\n",
        "                The cosine values, shape = [seq_len, rot_dim//2].\n",
        "        \"\"\"\n",
        "        theta = 1.0 / (self.config.rope_base_freq **\n",
        "                      (2 * jnp.arange(0, rot_dim // 2) / rot_dim))\n",
        "        positions = jnp.arange(seq_len, dtype=jnp.float32)\n",
        "        angles = positions[:, None] * theta[None, :]\n",
        "        return jnp.sin(angles), jnp.cos(angles)\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(\n",
        "        self,\n",
        "        q: Float[Array, \"batch seq_len num_heads head_dim\"],\n",
        "        k: Float[Array, \"batch seq_len num_heads head_dim\"]\n",
        "    ) -> Tuple[\n",
        "        Float[Array, \"batch seq_len num_heads head_dim\"],\n",
        "        Float[Array, \"batch seq_len num_heads head_dim\"]\n",
        "    ]:\n",
        "        \"\"\"\n",
        "        Applies rotary position embeddings to the first `rot_dim` channels\n",
        "        of query (q) and key (k) tensors. The remaining channels of each head\n",
        "        dimension are left unrotated.\n",
        "\n",
        "        Args:\n",
        "            q (Float[Array, \"batch seq_len num_heads head_dim\"]):\n",
        "                The query tensor.\n",
        "            k (Float[Array, \"batch seq_len num_heads head_dim\"]):\n",
        "                The key tensor.\n",
        "\n",
        "        Returns:\n",
        "            A tuple (q_rot, k_rot) where:\n",
        "            - q_rot (Float[Array, \"batch seq_len num_heads head_dim\"]):\n",
        "                The query tensor after applying partial RoPE.\n",
        "            - k_rot (Float[Array, \"batch seq_len num_heads head_dim\"]):\n",
        "                The key tensor after applying partial RoPE.\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, num_heads, head_dim = q.shape\n",
        "        rot_dim = int(self.config.rope_fraction * head_dim)\n",
        "\n",
        "        # Generate sine and cosine for the rotary transformation\n",
        "        sin, cos = self._get_rotary_matrix(seq_len, rot_dim)\n",
        "\n",
        "        # Reshape for broadcasting:\n",
        "        # sin, cos -> [1, seq, 1, rot_dim//2, 1]\n",
        "        sin = sin[None, :, None, :]\n",
        "        cos = cos[None, :, None, :]\n",
        "\n",
        "        def rotate_tensor(x: Float[Array, \"batch seq_len num_heads head_dim\"]\n",
        "                          ) -> Float[Array, \"batch seq_len num_heads head_dim\"]:\n",
        "            \"\"\"\n",
        "            Rotate the first `rot_dim` channels of x with the RoPE transformation.\n",
        "            \"\"\"\n",
        "            x_rot = x[..., :rot_dim].reshape(*x.shape[:-1], rot_dim // 2, 2)\n",
        "            x_rot = jnp.stack([\n",
        "                x_rot[..., 0] * cos - x_rot[..., 1] * sin,\n",
        "                x_rot[..., 0] * sin + x_rot[..., 1] * cos\n",
        "            ], axis=-1)\n",
        "\n",
        "            return jnp.concatenate([\n",
        "                x_rot.reshape(*x.shape[:-1], rot_dim),\n",
        "                x[..., rot_dim:]\n",
        "            ], axis=-1)\n",
        "\n",
        "        return rotate_tensor(q), rotate_tensor(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0JAICN195EW"
      },
      "source": [
        "### Testing RoPE on Key-Query Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsJ-l19O-Oui"
      },
      "outputs": [],
      "source": [
        "config = MiniMaxConfig(\n",
        "    # Rotate a fraction of dimensions (set <1.0 for partial rotation)\n",
        "    rope_fraction=0.5,\n",
        "    rope_base_freq=10000.0\n",
        ")\n",
        "\n",
        "rope_module = RotaryPositionEmbedding(config=config)\n",
        "\n",
        "batch_size = 1\n",
        "seq_length = 50\n",
        "num_heads = 4\n",
        "head_dim = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFHrW1nXDvUa"
      },
      "outputs": [],
      "source": [
        "# Random queries and keys for demonstration\n",
        "q = jnp.ones((batch_size, seq_length, num_heads, head_dim))\n",
        "k = jnp.ones((batch_size, seq_length, num_heads, head_dim))\n",
        "\n",
        "variables = rope_module.init(jax.random.PRNGKey(0), q, k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18euWoamDwx6"
      },
      "outputs": [],
      "source": [
        "q_rot, k_rot = rope_module.apply(variables, q, k)\n",
        "\n",
        "# Visualization of the rotated query tensor\n",
        "# Taking the first head from the first batch for visualization\n",
        "q_rot_np = np.array(q_rot[0, :, 0, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "b09vdq2OBnXN",
        "outputId": "25982efa-f9d6-4c6c-d3e0-ed030e0ef2b6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(20, 8))\n",
        "plt.imshow(q_rot_np, cmap='viridis', aspect='auto')\n",
        "plt.colorbar()\n",
        "plt.title('Rotary Positional Embeddings (Applied to Query)')\n",
        "plt.xlabel('Dimension')\n",
        "plt.ylabel('Position')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usAKjnfJFMJR"
      },
      "source": [
        "### Initialization Strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKipf32iFKhF"
      },
      "outputs": [],
      "source": [
        "xavier_uniform = nn.initializers.variance_scaling(\n",
        "    scale=1.0,\n",
        "    mode='fan_avg',\n",
        "    distribution='uniform'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExaWzeUHGnEt"
      },
      "source": [
        "## RMS Norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXmCvNvrV2sz"
      },
      "source": [
        "$$\n",
        "\\text{RMSNorm}(x) = g \\odot \\frac{x}{\\sqrt{\\frac{1}{d} \\sum_{i=1}^{d} x_i^2 + \\epsilon}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk05puqPVWfA"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements Root Mean Square Layer Normalization (RMSNorm) using Flax.\n",
        "\n",
        "    RMSNorm normalizes the input across the last dimension based on the\n",
        "    root mean square of the values in that dimension.\n",
        "\n",
        "    Attributes:\n",
        "        epsilon (float): A small constant added for numerical stability to\n",
        "            avoid division by zero.\n",
        "    \"\"\"\n",
        "    epsilon: float = 1e-6\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(\n",
        "        self,\n",
        "        x: Float[Array, \"batch seq_len hidden_size\"],\n",
        "    ) -> Float[Array, \"batch seq_len hidden_size\"]:\n",
        "        \"\"\"\n",
        "        Forward pass of the RMSNorm layer.\n",
        "\n",
        "        This normalizes the input tensor along its last dimension, then\n",
        "        optionally scales it by a learned parameter vector.\n",
        "\n",
        "        Args:\n",
        "            x (Float[Array, \"batch seq_len hidden_size\"]):\n",
        "                The input tensor of shape (batch, seq_len, hidden_size).\n",
        "\n",
        "        Returns:\n",
        "            Float[Array, \"batch seq_len hidden_size\"]:\n",
        "                The normalized output tensor of the same shape as the input.\n",
        "        \"\"\"\n",
        "        dtype = x.dtype\n",
        "\n",
        "        # Convert input to float32 for numerical stability in norm calculations\n",
        "        x = x.astype(jnp.float32)\n",
        "\n",
        "        g = self.param(\n",
        "            'scale',\n",
        "            nn.initializers.ones,\n",
        "            (x.shape[-1],)\n",
        "        )\n",
        "\n",
        "        rms = jnp.sqrt(\n",
        "            jnp.mean(jnp.square(x), axis=-1, keepdims=True) + self.epsilon\n",
        "        )\n",
        "\n",
        "        x_norm = x / rms\n",
        "\n",
        "        # Multiply by the learned scale, then cast back to the original dtype\n",
        "        return (g * x_norm).astype(dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsn0yY-GROHZ"
      },
      "source": [
        "# Softmax Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2b4CY3poVbN"
      },
      "source": [
        "## Equations\n",
        "##### Linear Projection\n",
        "$$\n",
        "Q = X W_Q + b_Q, \\quad K = X W_K + b_K, \\quad V = X W_V + b_V\n",
        "$$\n",
        "##### Reshaping\n",
        "$$\n",
        "Q \\in \\mathbb{R}^{(B, S, N_h, d_h)}, \\quad K, V \\in \\mathbb{R}^{(B, S, N_{kv}, d_h)}\n",
        "$$\n",
        "\n",
        "##### Rotatory Positional Embeddings\n",
        "$$\n",
        "Q' = \\text{RoPE}(Q), \\quad K' = \\text{RoPE}(K)\n",
        "$$\n",
        "\n",
        "##### Transpose for Attention Computation\n",
        "$$\n",
        "Q' \\in \\mathbb{R}^{(B, N_h, S, d_h)}, \\quad K' \\in \\mathbb{R}^{(B, N_{kv}, S, d_h)}, \\quad V \\in \\mathbb{R}^{(B, N_{kv}, S, d_h)}\n",
        "$$\n",
        "\n",
        "#####  Repeat K and V for Grouped Query Attention\n",
        "\n",
        "$$\n",
        "K'' = \\text{repeat}(K', \\text{group_size}, \\text{axis}=1) \\\\ V'' = \\text{repeat}(V, \\text{group_size}, \\text{axis}=1)\n",
        "$$\n",
        "\n",
        "##### Scaled Dot-Product Attention Score Computation\n",
        "$$\n",
        "A = \\frac{Q' K''^T}{\\sqrt{d_h}}\n",
        "$$\n",
        "\n",
        "##### Masking (if applied)\n",
        "\n",
        "$$\n",
        "\\begin{array}{c} A'_{ij} =\n",
        "\\begin{cases}\n",
        "A_{ij}, & \\text{if mask}_{ij} = 1 \\\\\n",
        "-10^9, & \\text{if mask}_{ij} = 0\n",
        "\\end{cases} \\end{array}\n",
        "$$\n",
        "\n",
        "##### Softmax Computation\n",
        "$$\n",
        "P = \\text{softmax}(A', \\text{axis}=-1)\n",
        "$$\n",
        "\n",
        "#####  Attention Output Computation\n",
        "$$\n",
        "O = P V''\n",
        "O \\in \\mathbb{R}^{(B, N_h, S, d_h)}\n",
        "$$\n",
        "\n",
        "\n",
        "##### Reshape and Final Projection\n",
        "$$\n",
        "O' = \\text{reshape}(\\text{transpose}(O, (0, 2, 1, 3)), (B, S, N_h \\cdot d_h))\n",
        "Y = O' W_O + b_O\n",
        "$$\n",
        "\n",
        "where $W_O \\in \\mathbb{R}^{(N_h \\cdot d_h, H)}$ projects back to the hidden size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0k-_ofj9mWf"
      },
      "outputs": [],
      "source": [
        "class SoftmaxAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements standard scaled dot-product attention with an optional\n",
        "    Grouped Query Attention (GQA) mechanism using repeated keys and values.\n",
        "    \"\"\"\n",
        "    config: MiniMaxConfig\n",
        "\n",
        "    def setup(self):\n",
        "        self.num_heads = self.config.num_heads\n",
        "        self.head_dim = self.config.head_dim\n",
        "        self.group_size = self.config.group_size   # => \"kv heads\"\n",
        "        self.hidden_size = self.config.hidden_size\n",
        "\n",
        "        # For GQA:\n",
        "        # - Q is projected to 64 heads\n",
        "        # - K, V are projected to only 8 heads, repeated at runtime.\n",
        "        self.num_kv_heads = self.num_heads // self.group_size  # 64 // 8 = 8\n",
        "\n",
        "        self.rope = RotaryPositionEmbedding(config=self.config)\n",
        "\n",
        "        self.q_proj = nn.Dense(features=self.num_heads * self.head_dim,\n",
        "                               kernel_init=xavier_uniform, name=\"q_proj\")\n",
        "        self.k_proj = nn.Dense(features=self.num_kv_heads * self.head_dim,\n",
        "                               kernel_init=xavier_uniform, name=\"k_proj\")\n",
        "        self.v_proj = nn.Dense(features=self.num_kv_heads * self.head_dim,\n",
        "                               kernel_init=xavier_uniform, name=\"v_proj\")\n",
        "        self.out_proj = nn.Dense(features=self.hidden_size,\n",
        "                               kernel_init=xavier_uniform, name=\"out_proj\")\n",
        "\n",
        "    def __call__(self,\n",
        "                 hidden_states: Float[Array, \"batch seq_len hidden_size\"],\n",
        "                 mask: Optional[Float[Array, \"batch 1 seq_len seq_len\"]] = None\n",
        "                ) -> Float[Array, \"batch seq_len hidden_size\"]:\n",
        "        \"\"\"\n",
        "        Forward pass of the softmax attention mechanism.\n",
        "\n",
        "        Args:\n",
        "            hidden_states: A float Tensor of shape (batch, seq_len, hidden_size),\n",
        "                where hidden_size can be num_heads * head_dim or similar.\n",
        "            mask: An optional boolean or float mask of shape\n",
        "                (batch, 1, seq_len, seq_len) indicating which positions\n",
        "                are valid (True) or invalid (False). If True means keep,\n",
        "                those entries are left as-is. If False, they are set\n",
        "                to a large negative number before softmax.\n",
        "\n",
        "        Returns:\n",
        "            A float Tensor of shape (batch, seq_len, hidden_size)\n",
        "            after applying the attention mechanism.\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, seq_len, _ = hidden_states.shape\n",
        "\n",
        "        q = self.q_proj(hidden_states)  # (b, s, 8192)\n",
        "        k = self.k_proj(hidden_states)  # (b, s, 1024)\n",
        "        v = self.v_proj(hidden_states)  # (b, s, 1024)\n",
        "\n",
        "        # Q => (b, s, 64, 128), K => (b, s, 8, 128), V => (b, s, 8, 128)\n",
        "        q = q.reshape(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        k = k.reshape(batch_size, seq_len, self.num_kv_heads, self.head_dim)\n",
        "        v = v.reshape(batch_size, seq_len, self.num_kv_heads, self.head_dim)\n",
        "\n",
        "        q, k = self.rope(q, k)\n",
        "\n",
        "        # Q => (b, 64, s, 128), K => (b, 8, s, 128), V => (b, 8, s, 128)\n",
        "        q = jnp.transpose(q, (0, 2, 1, 3))\n",
        "        k = jnp.transpose(k, (0, 2, 1, 3))\n",
        "        v = jnp.transpose(v, (0, 2, 1, 3))\n",
        "\n",
        "        # K, V => (b, 8, s, 128) => replicate 8 times => (b, 64, s, 128)\n",
        "        k = jnp.repeat(k, self.group_size, axis=1)\n",
        "        v = jnp.repeat(v, self.group_size, axis=1)\n",
        "\n",
        "        # Scaled dot-product attention => attn_scores => shape (b, 64, s, s)\n",
        "        attn_scores = jnp.einsum(\"bhqd,bhkd->bhqk\", q, k)\n",
        "        attn_scores = attn_scores / jnp.sqrt(self.head_dim)\n",
        "\n",
        "        # (Optional) Apply causal or padding mask\n",
        "        if mask is not None:\n",
        "            # mask shape is (b, 1, s, s), broadcast to (b, 64, s, s)\n",
        "            big_neg = jnp.array(-1e9, dtype=attn_scores.dtype)\n",
        "            attn_scores = jnp.where(mask, attn_scores, big_neg)\n",
        "\n",
        "        # Softmax over the last dimension (the \"key\" positions)\n",
        "        attn_probs = nn.softmax(attn_scores, axis=-1)\n",
        "\n",
        "        # Apply attention to values => (b, 64, s, 128)\n",
        "        attn_output = jnp.einsum(\"bhqk,bhkd->bhqd\", attn_probs, v)\n",
        "\n",
        "        # Reshape back to (b, s, 64*128=8192) => then project to 6144\n",
        "        attn_output = jnp.transpose(attn_output, (0, 2, 1, 3))\n",
        "        attn_output = attn_output.reshape(batch_size, seq_len, -1)\n",
        "\n",
        "        # Note, from the paper Sec. 2.0 ¶3, it's hard to understand the\n",
        "        # \"hidden size\" == 6144. Usually it's num_heads * head_dim (8192 for us)\n",
        "        # The assumption is that there is this down-projection at the end\n",
        "        return self.out_proj(attn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rln21YNaWu2_"
      },
      "source": [
        "### Testing Softmax Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ_9kfn2WwT7"
      },
      "outputs": [],
      "source": [
        "config = MiniMaxConfig(\n",
        "    num_heads=64,\n",
        "    head_dim=128,\n",
        "    group_size=8,\n",
        "    hidden_size=6144,\n",
        "    rope_fraction=0.5,\n",
        "    rope_base_freq=10000.0\n",
        ")\n",
        "\n",
        "attention = SoftmaxAttention(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huUt2tuugspP",
        "outputId": "a0b2a5da-8e4b-4dcd-99be-dc8d921e7c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter shapes:\n",
            "q_proj {'bias': (8192,), 'kernel': (6144, 8192)}\n",
            "k_proj {'bias': (1024,), 'kernel': (6144, 1024)}\n",
            "v_proj {'bias': (1024,), 'kernel': (6144, 1024)}\n",
            "out_proj {'bias': (6144,), 'kernel': (8192, 6144)}\n",
            "Output shape: (2, 10, 6144)\n"
          ]
        }
      ],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "batch, seq_len, hidden_size = 2, 10, 6144\n",
        "dummy_inputs = jnp.ones((batch, seq_len, hidden_size))\n",
        "\n",
        "mask = jnp.tril(jnp.ones((1, 1, seq_len, seq_len), dtype=bool))\n",
        "\n",
        "# Initialize parameters\n",
        "params = attention.init(rng, dummy_inputs, mask)\n",
        "print(\"Parameter shapes:\")\n",
        "for k, v in params[\"params\"].items():\n",
        "    print(k, jax.tree.map(jnp.shape, v))\n",
        "\n",
        "output = attention.apply(params, dummy_inputs, mask=mask)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZziqVl5jR0GD"
      },
      "source": [
        "# Mixture Of Experts\n",
        "$$\n",
        "h_t = \\sum_{i=1}^E\\text{Softmax}_i(\\text{TopK}(x_t\\cdot W_g))\\cdot FFN_i(x_t)\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPRPM1rLSK-O"
      },
      "source": [
        "TopK(·) denotes the operation that preserves the top 𝑘 scores among all 𝐸 experts while\n",
        "setting the remaining scores to −∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hy6frzT9qUy"
      },
      "outputs": [],
      "source": [
        "class ExpertMLP(nn.Module):\n",
        "    \"\"\"Implements individual expert FFN with hidden dimension expansion.\n",
        "\n",
        "    Args:\n",
        "        x: Input tensor of shape [batch, seq_len, hidden] or [tokens, hidden]\n",
        "\n",
        "    Returns:\n",
        "        Transformed tensor with same shape as input\n",
        "    \"\"\"\n",
        "    config: MiniMaxConfig\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x: Float[Array, \"... hidden_dims\"]) -> Float[Array, \"... hidden_dims\"]:\n",
        "        # Expand to intermediate dimension\n",
        "        x = nn.Dense(self.config.ffw_hidden_size,\n",
        "                   kernel_init=xavier_uniform,\n",
        "                   name=\"expert_expand\")(x)\n",
        "        x = nn.relu(x)\n",
        "        return nn.Dense(self.config.hidden_size,\n",
        "                      kernel_init=xavier_uniform,\n",
        "                      name=\"expert_contract\")(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QLWiQ9DD20v"
      },
      "source": [
        "#### Testing FFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZOSxGEuD4Z1",
        "outputId": "12470766-259c-47b8-d2f1-a545cc6e7e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== FFN Test ===\n",
            "Expand layer weights - Mean: 0.0000\n",
            "Expand layer weights - Std: 0.0114\n",
            "Contract layer weights - Mean: 0.0000\n",
            "Contract layer weights - Std: 0.0114\n"
          ]
        }
      ],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "dummy_input = jnp.ones((2, 5, 6144))\n",
        "expert = ExpertMLP(MiniMaxConfig())\n",
        "params = expert.init(rng, dummy_input)\n",
        "\n",
        "expand_weights = params['params']['expert_expand']['kernel']\n",
        "contract_weights = params['params']['expert_contract']['kernel']\n",
        "\n",
        "print(\"\\n=== FFN Test ===\")\n",
        "print(f\"Expand layer weights - Mean: {jnp.mean(expand_weights):.4f}\")\n",
        "print(f\"Expand layer weights - Std: {jnp.std(expand_weights):.4f}\")\n",
        "print(f\"Contract layer weights - Mean: {jnp.mean(contract_weights):.4f}\")\n",
        "print(f\"Contract layer weights - Std: {jnp.std(contract_weights):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohkR0PuE9oT-"
      },
      "outputs": [],
      "source": [
        "class GlobalRouter(nn.Module):\n",
        "    \"\"\"Handles token-to-expert routing with top-k selection and load balancing.\n",
        "\n",
        "    Args:\n",
        "        x: Flattened input tensor of shape [tokens, hidden]\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (expert indices, routing scores, expert mask, aux loss)\n",
        "    \"\"\"\n",
        "    config: MiniMaxConfig\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x: Float[Array, \"tokens hidden\"]\n",
        "                ) -> Tuple[Int[Array, \"tokens top_k\"],\n",
        "                           Float[Array, \"tokens top_k\"],\n",
        "                           Bool[Array, \"tokens top_k experts\"],\n",
        "                           Float[Array, \"\"]]:\n",
        "        gate_logits = nn.Dense(self.config.num_experts,\n",
        "                               kernel_init=xavier_uniform, name=\"router_gate\")(x)\n",
        "\n",
        "        # Top-k expert selection\n",
        "        scores, expert_indices = jax.lax.top_k(gate_logits, self.config.top_k)\n",
        "        scores = jax.nn.softmax(scores, axis=-1)\n",
        "\n",
        "        # Create expert assignment mask\n",
        "        expert_mask = jax.nn.one_hot(expert_indices, self.config.num_experts)\n",
        "\n",
        "        f_i = jnp.mean(expert_mask, axis=(0, 1))\n",
        "        m_i = jnp.mean(jax.nn.softmax(gate_logits, axis=-1), axis=0)  # Mean probs\n",
        "        aux_loss = self.config.aux_loss_coef * jnp.sum(f_i * m_i) / self.config.num_experts\n",
        "\n",
        "        return expert_indices, scores, expert_mask, aux_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fSqCHN4EGkb"
      },
      "source": [
        "#### Testing Global Router"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A8iDoUUEF9z",
        "outputId": "6839391e-fd4b-4f6c-f965-2a059edda953"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== GlobalRouter Test ===\n",
            "Expert indices shape: (10, 2)\n",
            "Routing scores shape: (10, 2)\n",
            "Expert mask shape: (10, 2, 32)\n",
            "Aux loss value: 0.0000\n",
            "Aux loss is scalar: True\n"
          ]
        }
      ],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "num_tokens = 10  # batch_size * seq_len\n",
        "dummy_input = jax.random.normal(rng, (num_tokens, 6144))\n",
        "\n",
        "router = GlobalRouter(MiniMaxConfig())\n",
        "params = router.init(rng, dummy_input)\n",
        "indices, scores, mask, loss = router.apply(params, dummy_input)\n",
        "\n",
        "print(\"\\n=== GlobalRouter Test ===\")\n",
        "print(f\"Expert indices shape: {indices.shape}\")\n",
        "print(f\"Routing scores shape: {scores.shape}\")\n",
        "print(f\"Expert mask shape: {mask.shape}\")\n",
        "print(f\"Aux loss value: {loss:.4f}\")\n",
        "print(f\"Aux loss is scalar: {loss.ndim == 0}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caoX_NFr9utu"
      },
      "outputs": [],
      "source": [
        "class MoEBlock(nn.Module):\n",
        "    \"\"\"MoE transformer block implementing token-drop strategy with capacity limits.\"\"\"\n",
        "    config: MiniMaxConfig\n",
        "\n",
        "    def setup(self):\n",
        "        self.router = GlobalRouter(self.config)\n",
        "        self.experts = [ExpertMLP(self.config) for _ in range(self.config.num_experts)]\n",
        "\n",
        "    def __call__(self, x: Float[Array, \"batch seq_len hidden\"]) -> Tuple[Float[Array, \"batch seq_len hidden\"], Float[Array, \"\"]]:\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        num_tokens = batch_size * seq_len\n",
        "        x_flat = x.reshape(num_tokens, -1)  # [tokens, hidden]\n",
        "\n",
        "        # Get routing decisions\n",
        "        expert_indices, scores, expert_mask, aux_loss = self.router(x_flat)\n",
        "\n",
        "        assert expert_indices.shape == (num_tokens, self.config.top_k), \"Expert indices shape mismatch\"\n",
        "        assert scores.shape == (num_tokens, self.config.top_k), \"Scores shape mismatch\"\n",
        "        assert expert_mask.shape == (num_tokens, self.config.top_k, self.config.num_experts), \"Expert mask shape mismatch\"\n",
        "\n",
        "        output = jnp.zeros_like(x_flat)\n",
        "        for expert_idx in range(self.config.num_experts):\n",
        "            output += self._process_expert(\n",
        "                x_flat,\n",
        "                expert_idx,\n",
        "                expert_mask[..., expert_idx],  # [tokens, top_k]\n",
        "                scores,  # [tokens, top_k]\n",
        "                num_tokens\n",
        "            )\n",
        "\n",
        "        return output.reshape(batch_size, seq_len, -1), aux_loss\n",
        "\n",
        "    def _process_expert(\n",
        "        self,\n",
        "        x: Float[Array, \"tokens hidden\"],\n",
        "        expert_idx: int,\n",
        "        mask: Bool[Array, \"tokens top_k\"],\n",
        "        scores: Float[Array, \"tokens top_k\"],\n",
        "        num_tokens: int\n",
        "    ) -> Float[Array, \"tokens hidden\"]:\n",
        "        \"\"\"Process tokens through a single expert with capacity constraints.\"\"\"\n",
        "        capacity = max((num_tokens * self.config.top_k) // self.config.num_experts, 1)\n",
        "\n",
        "        # Select tokens and scores with validation\n",
        "        tokens, scores_expert = self._select_tokens(x, scores, mask, capacity)\n",
        "        assert tokens.shape[0] <= capacity, \"Token selection exceeds capacity\"\n",
        "        assert scores_expert.shape == (capacity,), \"Scores shape mismatch\"\n",
        "\n",
        "        # Process through expert\n",
        "        expert_out = self.experts[expert_idx](tokens)\n",
        "        assert expert_out.shape == (capacity, self.config.hidden_size), \"Expert output shape mismatch\"\n",
        "\n",
        "        # Scatter outputs with dimension checks\n",
        "        scattered = self._scatter_outputs(\n",
        "            expert_out, scores_expert, mask, capacity, num_tokens\n",
        "        )\n",
        "        assert scattered.shape == (num_tokens, self.config.hidden_size), \"Scattering shape mismatch\"\n",
        "\n",
        "        return scattered\n",
        "\n",
        "    def _select_tokens(\n",
        "        self,\n",
        "        x: Float[Array, \"tokens hidden\"],\n",
        "        scores: Float[Array, \"tokens top_k\"],\n",
        "        mask: Bool[Array, \"tokens top_k\"],\n",
        "        capacity: int\n",
        "    ) -> Tuple[Float[Array, \"capacity hidden\"], Float[Array, \"capacity\"]]:\n",
        "        \"\"\"Select tokens for expert processing based on routing scores.\"\"\"\n",
        "\n",
        "        # Get raw indices [capacity, 2]\n",
        "        token_indices = jnp.argwhere(mask, size=capacity, fill_value=-1)\n",
        "\n",
        "        # Validate indices\n",
        "        assert token_indices.shape == (capacity, 2), f\"Indices shape {token_indices.shape} != ({capacity}, 2)\"\n",
        "\n",
        "        # Extract coordinates\n",
        "        i_indices = token_indices[..., 0]  # [capacity]\n",
        "        j_indices = token_indices[..., 1]  # [capacity]\n",
        "        valid_mask = (i_indices != -1) & (j_indices != -1)\n",
        "\n",
        "        # Get scores for selected positions\n",
        "        scores_expert = scores[i_indices, j_indices] * valid_mask\n",
        "\n",
        "        # Sort by scores (descending) with valid entries first\n",
        "        sort_order = jnp.argsort(-scores_expert)\n",
        "\n",
        "        return x[i_indices][sort_order], scores_expert[sort_order]\n",
        "\n",
        "    def _scatter_outputs(\n",
        "        self,\n",
        "        expert_out: Float[Array, \"capacity hidden\"],\n",
        "        scores: Float[Array, \"capacity\"],\n",
        "        mask: Bool[Array, \"tokens top_k\"],\n",
        "        capacity: int,\n",
        "        num_tokens: int\n",
        "    ) -> Float[Array, \"tokens hidden\"]:\n",
        "        \"\"\"Distribute expert outputs back to original token positions.\"\"\"\n",
        "        # Get token indices (i) from mask [capacity]\n",
        "        token_indices = jnp.argwhere(mask, size=capacity, fill_value=-1)[..., 0]\n",
        "        valid = token_indices != -1\n",
        "\n",
        "        # Calculate weighted outputs\n",
        "        weighted = expert_out * scores[:, None] * valid[:, None]\n",
        "\n",
        "        # Validate scattering dimensions\n",
        "        assert weighted.shape == (capacity, self.config.hidden_size), f\"Weighted shape {weighted.shape} mismatch\"\n",
        "        assert token_indices.shape == (capacity,), f\"Indices shape {token_indices.shape} mismatch\"\n",
        "\n",
        "        # Aggregate outputs\n",
        "        return jax.ops.segment_sum(\n",
        "            weighted,\n",
        "            token_indices,\n",
        "            num_segments=num_tokens\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8gr5qE1_XLM"
      },
      "source": [
        "### Testing MoE Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9lgZeFm_ZoS"
      },
      "outputs": [],
      "source": [
        "config = MiniMaxConfig(\n",
        "    ffw_hidden_size=9216,\n",
        "    num_experts=8,\n",
        "    top_k=2,\n",
        "    hidden_size=6144\n",
        ")\n",
        "batch_size = 4\n",
        "seq_len = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq_5K7fZ_bOk",
        "outputId": "777ced81-7d9e-46f9-83a4-ea1de836cea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Creating MoE Block ===\n",
            "Config: MiniMaxConfig(ffw_hidden_size=9216, num_experts=8, top_k=2, aux_loss_coef=0.01, num_heads=64, head_dim=128, group_size=8, num_layers=80, linear_per_softmax=7, hidden_size=6144, deepnorm_alpha=0.81, rope_fraction=0.5, rope_base_freq=10000)\n",
            "MoE block created with:\n",
            "- 8 experts\n",
            "- Top-2 routing\n",
            "- Expert hidden size: 9216\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== Creating MoE Block ===\")\n",
        "print(f\"Config: {config}\")\n",
        "moe_block = MoEBlock(config)\n",
        "print(\"MoE block created with:\")\n",
        "print(f\"- {config.num_experts} experts\")\n",
        "print(f\"- Top-{config.top_k} routing\")\n",
        "print(f\"- Expert hidden size: {config.ffw_hidden_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HRw2a9h_jWV"
      },
      "outputs": [],
      "source": [
        "rng = jax.random.PRNGKey(0)\n",
        "dummy_input = jax.random.normal(rng, (batch_size, seq_len, config.hidden_size))\n",
        "params = moe_block.init(rng, dummy_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa9vTcaW_XBi",
        "outputId": "27ebf796-141b-4cdf-afdd-971272e150c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MoE Block Forward Pass ===\n",
            "Input shape: (4, 512, 6144)\n",
            "Input stats - Mean: -0.0008, Std: 0.9996\n",
            "\n",
            "=== Output Verification ===\n",
            "Output shape: (4, 512, 6144)\n",
            "Output matches input shape: True\n",
            "Output stats - Mean: 0.0022, Std: 0.5265\n",
            "\n",
            "=== Auxiliary Loss Check ===\n",
            "Aux loss value: 0.0002\n",
            "Aux loss is scalar: True\n",
            "\n",
            "=== Sanity Checks ===\n",
            "Output is all zeros: False\n",
            "Gate weights shape: (6144, 8)\n",
            "Gate bias shape: (8,)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n=== MoE Block Forward Pass ===\")\n",
        "# Generate test input with random values\n",
        "test_input = jax.random.normal(rng, (batch_size, seq_len, config.hidden_size))\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "print(f\"Input stats - Mean: {jnp.mean(test_input):.4f}, Std: {jnp.std(test_input):.4f}\")\n",
        "\n",
        "# Run forward pass\n",
        "output, aux_loss = moe_block.apply(params, test_input)\n",
        "\n",
        "print(\"\\n=== Output Verification ===\")\n",
        "print(f\"Output shape: {output.shape}\")\n",
        "print(f\"Output matches input shape: {output.shape == test_input.shape}\")\n",
        "print(f\"Output stats - Mean: {jnp.mean(output):.4f}, Std: {jnp.std(output):.4f}\")\n",
        "\n",
        "print(\"\\n=== Auxiliary Loss Check ===\")\n",
        "print(f\"Aux loss value: {aux_loss:.4f}\")\n",
        "print(f\"Aux loss is scalar: {aux_loss.ndim == 0}\")\n",
        "\n",
        "print(\"\\n=== Sanity Checks ===\")\n",
        "# Verify non-zero output\n",
        "print(f\"Output is all zeros: {jnp.allclose(output, 0)}\")\n",
        "\n",
        "# Verify expert diversity\n",
        "gate_params = params['params']['router']['router_gate']\n",
        "print(f\"Gate weights shape: {gate_params['kernel'].shape}\")\n",
        "print(f\"Gate bias shape: {gate_params['bias'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA0Hu90qHAh2"
      },
      "source": [
        "# Classical Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oniBl-1uHFWl"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zOTAUjf9-M9"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    config: MiniMaxConfig\n",
        "\n",
        "    # in progress"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "jax",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
