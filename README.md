# A Survey on State-of-the-Art Attention Mechanisms

### Tasks:

- [X] Translate Notebook into Repo
- [ ] Notebook transformer block
- [ ] Model sharding -> /sharding branch
- [ ] Dataset
- [ ] Evals
- [ ] Add more...
